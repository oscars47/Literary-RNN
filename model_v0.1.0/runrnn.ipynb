{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 04:16:45.830716: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-10 04:16:45.939366: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-10 04:16:45.942086: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-10 04:16:45.942098: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-10 04:16:46.277683: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-10 04:16:46.277711: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-10 04:16:46.277714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 04:16:47.089600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-10 04:16:47.090160: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-10 04:16:47.090182: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-10 04:16:47.090198: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-10 04:16:47.090215: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-10 04:16:47.090232: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-10 04:16:47.090255: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-10 04:16:47.090272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-10 04:16:47.090286: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-10 04:16:47.090290: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moscarscholin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221210_041648-2640hjoe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0/runs/2640hjoe\" target=\"_blank\">solar-wind-9</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Additional properties are not allowed ('goal' was unexpected)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 2. 'val_loss' is not of type 'object'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 69u12s4r\n",
      "Sweep URL: https://wandb.ai/oscarscholin/Thinking-Parrot2.0/sweeps/69u12s4r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: Synced solar-wind-9: https://wandb.ai/oscarscholin/Thinking-Parrot2.0/runs/2640hjoe\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20221210_041648-2640hjoe/logs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: byrutwea with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_1: 206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_2: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_3: 83\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_4: 218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_5: 72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2596728364930626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09468993032858795\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221210_041657-byrutwea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0/runs/byrutwea\" target=\"_blank\">worldly-sweep-1</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0/sweeps/69u12s4r\" target=\"_blank\">https://wandb.ai/oscarscholin/Thinking-Parrot2.0/sweeps/69u12s4r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 04:17:00.426946: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "126/126 [==============================] - ETA: 0s - loss: 3.6663\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.1\n",
      "----- Generating with seed: \"eheat function.DEFROST FUNCTION (Refe to Pg 5)When using bread straight f\"\n",
      "  g oi     cn neneanie nn  nbe ine  ueneeine y  edeee e eGo nia  e rceonbe gneee en  u e oe  edeh  er go. hee th oe   e cpn     t rN   r nn  uni N e  be  iep  n e  ta eecden  i th ne nshe     t    eiiif eeie eop  tn  ee e u   e     nern n rnee ee    ngn     i   e   in  a een  n  eeee   h eic  ci c nr  newleen  enci  hf hn.h   u e e   he  tn  ibeesi    ctht  e oNune ieneee   h n1enR .ee e    nb  no\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" n rnee ee    ngn     i   e   in  a een  n  eeee   h eic  ci c nr  newleen  enci  hf hn.h   u e e   he  tn  ibeesi    ctht  e oNune ieneee   h n1enR .ee e    nb  no to Pg 5)When using bread straight f\"\n",
      " i     o   e enehoe p eene e necee eeeete eue in   d  i h    eeeeoiee e  n b  ng eeo enc  ie  c h ee l ep eia  eiiei  dcee   e e    eee huc  ine  o.escr  i s oe p    n e    p e eee nlei nee   ee her eiue  in  n y  n eeoan    e n e    b o e eedeec  e a   e deeeeern eennd e ni  y hoeN  se   ee  en  eeeene  n e epn er.ee ei   h     e e ee e acee s ee eteee eynn fi,oe ecab t   A ie i o e n   eo  hn  .\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"o e eedeec  e a   e deeeeern eennd e ni  y hoeN  se   ee  en  eeeene  n e epn er.ee ei   h     e e ee e acee s ee eteee eynn fi,oe ecab t   A ie i o e n   eo  hn  . to Pg 5)When using bread straight f\"\n",
      "o    hieCeearn hn een  endnee pe o  oh eene e  e nec btei eo ccen e eecehee ie    eie tne eeen e dihsni i eebeeoin inee e e e enoi eoeny  ce   ens e b p c  i ei   C e ac e ne lae eoo h  ie  ehi  nn d innae eaogncn eeeei ndn c  eei  e. eeei  t onc   den    .ee   e  eenoi e e ee  n eooe c ec    ebno n hnih hebe  .ynne  ahge ee n  .etcnee  ny b.ncee eeebait eneos e.  ne  ee e  n be  naecnei  eiCne ee\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"eei  t onc   den    .ee   e  eenoi e e ee  n eooe c ec    ebno n hnih hebe  .ynne  ahge ee n  .etcnee  ny b.ncee eeebait eneos e.  ne  ee e  n be  naecnei  eiCne ee to Pg 5)When using bread straight f\"\n",
      "  eeesio n   re      ce  e   ne  ne .enn  eee onei eee. e  ee    r ne ceen   t hl cn d   ee o r.iih  eee en eene      .  e  neceli.o  c    eb eiu u ean  enc  alnn  eneib n ien en e e n e en eeoeenanen ee   e  oeeb o nn   ec   e ne  gn eo  heeens  e ce i  e  bcreoe ce e e heini eoen n e eoei pieeonceee t annn eeieee  etebne      o   o.g t    n s nin eme  e   ne se ane  e heie   eies ecsl re  sen e \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"o  heeens  e ce i  e  bcreoe ce e e heini eoen n e eoei pieeonceee t annn eeieee  etebne      o   o.g t    n s nin eme  e   ne se ane  e heie   eies ecsl re  sen e  to Pg 5)When using bread straight f\"\n",
      " eooieeencg nen nene     icreei iie  r net eeb e en  s  c1N   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7ff61458ae50> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_communicate_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMessageFuture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re t oc.ri e.o n    e  h h n  e d i   en oee  e   l e  ce c.b   ee nD.eono  d e ee ciec ib oee e  he ce.  iie e be.ei  n e  c h  eceo   c ennii  n i  euoie eye    ea i    e r eeene db nee e  l e. ie e d  c  a eeeee e  eod eseee     eo re   e n na  ce  e oe ee e ne nouee n n    ncco eo pnn  c  eo ao n  en hh.c no   e eR o ec niboe   eug.\n",
      "----- diversity: 1.5\n",
      "----- Generating with seed: \" eeene db nee e  l e. ie e d  c  a eeeee e  eod eseee     eo re   e n na  ce  e oe ee e ne nouee n n    ncco eo pnn  c  eo ao n  en hh.c no   e eR o ec niboe   eug. to Pg 5)When using bread straight f\"\n",
      "e   e ee isE   eC  n el e.eo ie eee     re.  h  e   ntbe.nee  eneeecl ie   ee ee e renene   ui i eeeennn  eae ee ner ic penen  e ei e s  nceeo ne   oo eeo oee c yee ce t coh  o     e enso cn n  eeene  ehcc e neeeehn    o ieetiedn eec eseeeee e e ee hde n es nan  Io iE eee b  ee oe enh ee  a  eet cee eeo eee n ene en i     e n  c   O n  e .ne o     o nirn   anetcebcc  l ne  nr see  es e oy eenee ia\n",
      "----- diversity: 2.0\n",
      "----- Generating with seed: \"eeeee e e ee hde n es nan  Io iE eee b  ee oe enh ee  a  eet cee eeo eee n ene en i     e n  c   O n  e .ne o     o nirn   anetcebcc  l ne  nr see  es e oy eenee ia to Pg 5)When using bread straight f\"\n",
      "d  e a i  ne  sn  n eee   cneece  c i       oe n r aie re     ue. i     ee   e  sie  h eh  ee    n   heeet s    e  ibe enenne  ee t  i  en    i  ftc tnboo  ee   ecrn  ne ei Rcae    e ece e i onc nsces  e    neee oee oee oie cnd  ge ei. e e n  e en  eeeegcc n tn de ew   een  in  u er lere e ee   ne s   ee    tce e ee i e e nee  pnai  c  ne    o n   secoe chcnn  eieo een   seeoneee  eeoehi .  e  e h\n",
      "\n",
      "Epoch 1: loss improved from inf to 3.66629, saving model to models/shakespeare_v0.0.1.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221210_041648-2640hjoe/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221210_041648-2640hjoe/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221210_041648-2640hjoe/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 206s 2s/step - loss: 3.6663 - val_loss: 3.3147 - lr: 0.0947\n",
      "Epoch 2/5\n",
      "  8/126 [>.............................] - ETA: 58s - loss: 3.2324"
     ]
    }
   ],
   "source": [
    "# file to train network\n",
    "# @oscars47\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "from wandb.keras import *\n",
    "\n",
    "# check GPU num\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "from dataprep2 import TextData # import TextData class for processing\n",
    "from modelpredict2 import * # get functions to interpret output\n",
    "\n",
    "# define path\n",
    "MAIN_DIR = '/home/oscar47/Desktop/thinking_parrot'\n",
    "DATA_DIR = os.path.join(MAIN_DIR, 'texts_prep') # main\n",
    "#DATA_DIR = os.path.join(MAIN_DIR, 'texts_prep', 'test') # for testing\n",
    "\n",
    "# define master txt file\n",
    "MASTER_TEXT_PATH = os.path.join(MAIN_DIR, 'texts', 'master.txt')\n",
    "#MASTER_TEXT_PATH = os.path.join(MAIN_DIR, 'texts', 'toaster_man.txt')\n",
    "\n",
    "# initialize text object\n",
    "maxChar = 100\n",
    "master=TextData(MASTER_TEXT_PATH, maxChar)\n",
    "# get alphabet\n",
    "alphabet = master.alphabet\n",
    "char_to_int= master.char_to_int\n",
    "int_to_char = master.int_to_char\n",
    "text = master.text\n",
    "\n",
    "# read in files for training\n",
    "x_train = np.load(os.path.join(DATA_DIR, 'x_train.npy'))\n",
    "y_train = np.load(os.path.join(DATA_DIR, 'y_train.npy'))\n",
    "x_val = np.load(os.path.join(DATA_DIR, 'x_val.npy'))\n",
    "y_val = np.load(os.path.join(DATA_DIR, 'y_val.npy'))\n",
    "\n",
    "# build model functions--------------------------------\n",
    "def build_model(LSTM_layer_size_1,  LSTM_layer_size_2, LSTM_layer_size_3, \n",
    "          LSTM_layer_size_4, LSTM_layer_size_5, \n",
    "          dropout, learning_rate):\n",
    "    # call initialize function\n",
    "    \n",
    "    model = Sequential()\n",
    "    # RNN layers for language processing\n",
    "    model.add(LSTM(LSTM_layer_size_1, input_shape = (2*maxChar, len(alphabet)), return_sequences=True))\n",
    "    model.add(LSTM(LSTM_layer_size_2, return_sequences=True))\n",
    "    model.add(LSTM(LSTM_layer_size_3, return_sequences=True))\n",
    "    model.add(LSTM(LSTM_layer_size_4, return_sequences=True))\n",
    "    model.add(LSTM(LSTM_layer_size_5))\n",
    "\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(len(alphabet)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    # put structure together\n",
    "    optimizer = RMSprop(learning_rate = learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    return model\n",
    "\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "    # If called by wandb.agent, as below,\n",
    "    # this config will be set by Sweep Controller\n",
    "      config = wandb.config\n",
    "\n",
    "      #pprint.pprint(config)\n",
    "\n",
    "      #initialize the neural net; \n",
    "      global model\n",
    "      model = build_model(config.LSTM_layer_size_1,  config.LSTM_layer_size_2, config.LSTM_layer_size_3, \n",
    "              config.LSTM_layer_size_4, config.LSTM_layer_size_5, \n",
    "              config.dropout, config.learning_rate)\n",
    "      \n",
    "      #now run training\n",
    "      history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size = config.batch_size,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=config.epochs,\n",
    "        callbacks=callbacks #use callbacks to have w&b log stats; will automatically save best model                     \n",
    "      ) \n",
    "\n",
    "# helper functions from Keras\n",
    "\n",
    "# do this each time we begin a new epoch    \n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = np.random.randint(1, len(text) - maxChar - 1)\n",
    "    # need to check how much to pad\n",
    "    if start_index < maxChar:\n",
    "        sentence0 = text[0:start_index]\n",
    "        sentence1 = text[start_index+1: start_index+start_index]\n",
    "        sentence = sentence0+sentence1\n",
    "    else:\n",
    "        stdev = (1/2)*(maxChar - 1)\n",
    "        mean = (maxChar - 1)\n",
    "        toast_len = int(np.random.normal(mean, stdev)) # get normalized-skewed toast length\n",
    "        sentence0 = text[start_index-toast_len:start_index]\n",
    "        sentence1 = text[start_index+1: start_index+toast_len]\n",
    "        sentence =  sentence0+ sentence1\n",
    "    \n",
    "\n",
    "    # 1. compute difference from maxChar and len/2\n",
    "    diff = maxChar - int(len(sentence)/2)\n",
    "    # 2. initialize new string for each sentence\n",
    "    complete_sentence = ''\n",
    "    for i in range(diff):\n",
    "        complete_sentence+='£' # appending forbidden\n",
    "    # 3. now add 'real' sentence\n",
    "    complete_sentence+=sentence\n",
    "    # 4. append forbidden again\n",
    "    for i in range(diff):\n",
    "        complete_sentence+='£'\n",
    "\n",
    "\n",
    "    for diversity in [0.1, 0.5,1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        #generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        #sys.stdout.write(generated)\n",
    "\n",
    "        # generate 400 characters worth of test\n",
    "        for i in range(400):\n",
    "            # prepare chosen sentence as part of new dataset\n",
    "            x_pred = np.zeros((1, 2*maxChar, len(alphabet)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                if char != '£': # encode 1 iff it's not padded\n",
    "                    x_pred[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "            # use the current model to predict what outputs are\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            # call the function above to interpret the probabilities and add a degree of freedom\n",
    "            next_index = sample(preds, diversity)\n",
    "            #convert predicted number to character\n",
    "            next_char = int_to_char[next_index]\n",
    "\n",
    "            generated+=next_char\n",
    "\n",
    "            # check size of sentence; if still small can keep old stuff in sentence0\n",
    "            if len(sentence) >= 2*maxChar:\n",
    "                sentence0 = sentence0[1:]\n",
    "            sentence0 += next_char # append new middle character\n",
    "            sentence=sentence0+sentence1 # append to main sentence\n",
    "\n",
    "            # print the new character as we create it\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "# define search parameters-----------------\n",
    "# holds wandb config nested dictionaries\n",
    "# @oscars47\n",
    "\n",
    "# set dictionary with random search; optimizing val_loss\n",
    "sweep_config= {\n",
    "    'method': 'random',\n",
    "    'name': 'val_loss',\n",
    "    'goal': 'minimize'\n",
    "}\n",
    "\n",
    "sweep_config['metric']= 'val_loss'\n",
    "\n",
    "# now name hyperparameters with nested dictionary\n",
    "parameters_dict = {\n",
    "    'epochs': {\n",
    "       'value':5\n",
    "    },\n",
    "    # for build_dataset\n",
    "     'batch_size': {\n",
    "       'distribution': 'int_uniform',  #we want to specify a distribution type to more efficiently iterate through these hyperparams\n",
    "       'min': 64,\n",
    "       'max': 128\n",
    "    },\n",
    "    'LSTM_layer_size_1': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'LSTM_layer_size_2': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'LSTM_layer_size_3': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'LSTM_layer_size_4': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'LSTM_layer_size_5': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "     'dropout': {\n",
    "             'distribution': 'uniform',\n",
    "       'min': 0,\n",
    "       'max': 0.6\n",
    "    },\n",
    "    'learning_rate':{\n",
    "         #uniform distribution between 0 and 1\n",
    "         'distribution': 'uniform', \n",
    "         'min': 0,\n",
    "         'max': 0.1\n",
    "     }\n",
    "}\n",
    "\n",
    "# append parameters to sweep config\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "# login to wandb-------------------------\n",
    "wandb.init(project=\"Thinking-Parrot2.0\", entity=\"oscarscholin\")\n",
    "\n",
    "# finish with callbacks------------\n",
    "# use the two helper functions above to create the LambdaCallback \n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "# define two other callbacks\n",
    "# save model\n",
    "# if no directory \"models\" exists, create it\n",
    "if not(os.path.exists('models')):\n",
    "    os.mkdir('./models/')\n",
    "modelpath = \"models/shakespeare_v0.0.1.hdf5\"\n",
    "checkpoint = ModelCheckpoint(modelpath, monitor='loss',\n",
    "                             verbose=1, save_best_only=True,\n",
    "                             mode='min')\n",
    "# if learning stals, reduce the LR\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)\n",
    "\n",
    "# compile the callbacks\n",
    "callbacks = [print_callback, checkpoint, reduce_lr, WandbCallback()]\n",
    "\n",
    "# initialize sweep!\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Thinking-Parrot2.0\", entity=\"oscarscholin\")\n",
    "\n",
    "# 'train' tells agent function is train\n",
    "# 'count': number of times to run this\n",
    "wandb.agent(sweep_id, train, count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aaf8a3611b879056867134183afc22ea709e115b10fb7684e1dbf805b3500c4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
