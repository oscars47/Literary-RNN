{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 10:21:12.196229: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 10:21:12.342701: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-12 10:21:12.364568: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-12 10:21:12.364577: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-12 10:21:12.828489: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-12 10:21:12.828526: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-12 10:21:12.828529: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 10:21:13.834300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 10:21:13.835185: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-12 10:21:13.835238: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-12 10:21:13.835272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-12 10:21:13.835306: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-12 10:21:13.835338: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-12 10:21:13.835367: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-12 10:21:13.835396: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-12 10:21:13.835425: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-12 10:21:13.835430: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'æ', 'é', 'ê', 'ï', '—', '‘', '’', '“', '”']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moscarscholin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221212_102119-1luxieqo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0/runs/1luxieqo\" target=\"_blank\">worthy-disco-2</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Additional properties are not allowed ('goal' was unexpected)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 2. 'val_loss' is not of type 'object'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: bojamggc\n",
      "Sweep URL: https://wandb.ai/oscarscholin/Thinking-Parrot2.0/sweeps/bojamggc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: Synced worthy-disco-2: https://wandb.ai/oscarscholin/Thinking-Parrot2.0/runs/1luxieqo\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20221212_102119-1luxieqo/logs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rvvsrx4z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_1: 74\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_2: 252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_3: 127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_4: 65\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_5: 81\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.08305229945336183\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0012862330925389354\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221212_102128-rvvsrx4z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0/runs/rvvsrx4z\" target=\"_blank\">eager-sweep-1</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0/sweeps/bojamggc\" target=\"_blank\">https://wandb.ai/oscarscholin/Thinking-Parrot2.0/sweeps/bojamggc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 10:21:31.008119: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4603/4603 [==============================] - ETA: 0s - loss: 3.0897\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.1\n",
      "199\n",
      "53\n",
      "----- Generating with seed: \" than that thou shouldst betorn asunder by wild horse\"\n",
      " ea  e           e    cah e   hh l   seean a eh  eh   et  a       h   e  ai e yes  etd  o ,nhaee   ht   e efd  n  eo  etn a  a         f a s aae ae r  ntl t    tr     lao a    r iae           e   ah  ee o  eal he u   o n eas   e        m t e gt  e etr n e  d  en ,   s ha h t  eo h eie )h  a      d     eetot a ig   i  ae        t ee   e r e h i  o e ne    na   eeetr     ere da f     ha he   a i   e\n",
      "----- diversity: 0.5\n",
      "199\n",
      "81\n",
      "----- Generating with seed: \" enough your worth to sing:    For we, whch now behold these present days,    Hav\"\n",
      "oaha e e oai    h ta       e  ea      ia    ai t  et a   y  h    ahe  eehte tn a    s    e   ne    iiee l  da  oa     ne  ah    i oaiea   n etnh    Settn  lmi  o    e      h          da   eh   iaaa , hpn ee    h e  a  tfni    tlhn it   e he ho        rne ia    o ee  i se   e e    oe aieh oto    t    ep  neee  ea  aoe   e o  rli      o a t     ne  eh    oi  e      n     t  a       r  dgm  e  a eran\n",
      "----- diversity: 1.2\n",
      "199\n",
      "165\n",
      "----- Generating with seed: \" in 1769, \"printed for the Translator,\" was an impudentimposture, being nothing mor than Motteux's version with a few of thewords, here and there, artfully transpose\"\n",
      "e   e    aa i t         oe        id    a   a  deeee oaa  ee  b oo  is e       ae  ea   ia ea    e    ie r    rl o  fi  d ae  en  aa   i teti daa     r g  i n ea is od     d ea a    s    ihoh e    sedem r  e  e aroes    ir o     a     ts  ee    ihih e  h lb shh t s tr     e  h   ee     ei  t hdh teaa re  a yo a   ct  ese s ao      e dH   u  e  lce esn      r e  n s n hd e i,  t      i d tw  e t   \n",
      "\n",
      "Epoch 1: loss improved from inf to 3.08972, saving model to /home/oscar47/Desktop/thinking_parrot/tp2_v0.0.1.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221212_102119-1luxieqo/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221212_102119-1luxieqo/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221212_102119-1luxieqo/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4603/4603 [==============================] - 2927s 635ms/step - loss: 3.0897 - val_loss: 3.2369 - lr: 0.0013\n",
      "Epoch 2/5\n",
      "4603/4603 [==============================] - ETA: 0s - loss: 3.0836\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.1\n",
      "199\n",
      "175\n",
      "----- Generating with seed: \"nation, personally attended to the mending of the saint’s roof that night 142 The saint hanna was a farmer One day he set off to plough but gave away all his seed to feed the \"\n",
      " e   g  t thunoae  e r t    etn aeh e a  h nah ai a   eoec     l i th    s  i eee e h esn,oih  i     s a d        h   f  eo  itp   fn tt ne        t eiae     aot  g     at  ,h D d  ege  hanasa  re                a a cre r  r    ekn an  eon     u  h ea,t  a  dt d   nta a  tm i t ttao n  p t a   a    te      ea   e     s  dts he a i ma r  ,he  ir a    odoai es  c    e   toes lr e      de e e e    hh\n",
      "----- diversity: 0.5\n",
      "199\n",
      "75\n",
      "----- Generating with seed: \"uixote to deposit his armour.Gustave Dre makes it an elaborate fountain suc\"\n",
      "o  a   nts  h b    o atae  oou u h  eohnh      a r    aa h  e  t   e s,eo n a eeeas ie ae  d u ei d  hs   a ,     ertn   e le  thheo    e  t r i eenf  p ha so  ai eehoe tr  ae hahe  ee r    he e  eh rtate    a     oi tr e    o hau oh s  ee eie    aea ,naeti ec at   aa       o    s  seh iw esa        nn  rth    ca nu e nt   niahlo    n   e     a eda sgi hte rb  eh c a s he    te    s    p    e  dre\n",
      "----- diversity: 1.2\n",
      "199\n",
      "163\n",
      "----- Generating with seed: \"errantry, if they had any at all, were of the vaguest, who hadnever seen or heard f a book of chivalry, who could not possibly feelthe humour of the burlesque or s\"\n",
      "shre ha   o e    taien  tn nii atwa e gmlen     o        i h   s  e  ee   e ginde ioi he soo    o   hi ie d    aaeaeel ida   tef ite e i       rrl n    o ee       ic   e n     oee     a  da  e   t e    t  de ao  ,ero tf hmu e  Ba,,   t h e   h     eoo ti eo a n oa c  intsa  fnhI tr nn  ea  e o    a  r      hr hree  ad a  o   l      tiiad n n hlht  ld    h  trb   omo f i e t   i  na    i ieh  s    \n",
      "\n",
      "Epoch 2: loss improved from 3.08972 to 3.08364, saving model to /home/oscar47/Desktop/thinking_parrot/tp2_v0.0.1.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221212_102119-1luxieqo/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221212_102119-1luxieqo/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221212_102119-1luxieqo/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4603/4603 [==============================] - 2951s 641ms/step - loss: 3.0836 - val_loss: 3.2252 - lr: 0.0013\n",
      "Epoch 3/5\n",
      "4603/4603 [==============================] - ETA: 0s - loss: 3.0828\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.1\n",
      "199\n",
      "197\n",
      "----- Generating with seed: \"hough crows cry out against him in the marshes, and though they draw near with their cawing as if tey were about to attack him? He, for his part, takes the wise course: he flies away, and lets them\"\n",
      "i r    toaee     bs   e ae acd    enaeit s  t i  et a  e s  ee n e hehde aa e  e l a  i ao  e rw h  eeeM  n    s-  i tarh e  u h lr  a er e ae   sai     ae l   o a eo  h  tsl     e   i eorcetoa    t   h  el   e ie  n  ah    e  o  r  e  ad   e    d eo eahe i e e   t  d r  n  det h  haor   e    o   e e  t e   sf   ,h  c i a tes    laas tA  raret    p  a,f  ea  tenceh      r n   stt  e       wn eeeef\n",
      "----- diversity: 0.5\n",
      "199\n",
      "139\n",
      "----- Generating with seed: \". In order to make a claim under the Warranty, the Owner must, where pssiblereturn the goods to the Seller’s store at the Owner’s cost. Pro\"\n",
      "  aao   n   s ne      e      ht  e hn      ru,eer ge   ta  a n    a is   a h  ah   s   -   lhe  f  de l oi  yee    a  e          tTa  e   e rdfh     n o i.   h h  i tr   nh    a a  ia ef teohe ne  heona e          y a    a    e   nst    aoaa  e  r     d iem  i  i      elee   et oee , eta ene t  ae  ew h bia n t a  iadei ie ensaene  re e r e   a   ,t h d    ao  dou   e  r l   te     oo E  e e  t ma\n",
      "----- diversity: 1.2\n",
      "199\n",
      "167\n",
      "----- Generating with seed: \"e javade jogi 57 jogiyajiajyo 116 jogiya ji nisadina 44 jogiya ne kahajyo 117 jogiyai pritari 54 jogiya se prita kiyarp 53 jogI mata ja mata ja 46 jogi mhamne darasa d\"\n",
      "e tlo   eees a a  hett lrea n      ee    l e        l o   i a  aey   i  e, mh ad a e   n  h ried ed m  ra no   ar e a h   ne e n    e a  i       i h  oo  oii i eua  nal   a iee  t es  meto ea e t i  eo e th   a l earia ho a toa i r  r  i e     , t     l satt nf e nh r    e  e  ees    e i h    -     oA     ie r ei   ld   pad aa o e t hahl t   eAh   lha se    ttetf teoe  , hI     o    ee    t e  i  \n",
      "\n",
      "Epoch 3: loss improved from 3.08364 to 3.08285, saving model to /home/oscar47/Desktop/thinking_parrot/tp2_v0.0.1.hdf5\n",
      "4603/4603 [==============================] - 2954s 642ms/step - loss: 3.0828 - val_loss: 3.2316 - lr: 0.0013\n",
      "Epoch 4/5\n",
      "4603/4603 [==============================] - ETA: 0s - loss: 3.0826\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.1\n",
      "199\n",
      "157\n",
      "----- Generating with seed: \"ich, if he mistook not, there would be no question.Of this dramatic masterpiecethe world has no opportunity of judging; hishealth had been failing for some t\"\n",
      " w  l  h eion  la- I      ena   ee ee n n  ee a   h  t e  t  a et  ,ihhe ono   e        t e e e    a faon   dae re n    t   a c   sea etiet   do ti oaiai   e e e e    a     e     ee    to ha eeng  eo  n e e   av lh     e o   , ssle  .o  ee e as   h           gete t  te  r h n aieeat  h;hehm      e  ahf a  s  h e  ese     d       die hv   uo  ef   s  T eh    s  s   en   oho h rioen en I a e  r  a h\n",
      "----- diversity: 0.5\n",
      "199\n",
      "181\n",
      "----- Generating with seed: \" Chatur- vedi’s editition does not aim to be all-inclusive Svami Ananda Svarup’s “Mira Sudhsindhu” contains 1312 songs and Padmavati “Shabnam’s” “Brihad Pada Sangraha” 590 The last-\"\n",
      " e6   i  e n o ial e  h  n  n   t  nrauB tt   oha   en ei     ai  a  iin   i   , a dtp hh  a  os  etd aoe  t ar  egt eo  n i  te, ,a in otel  ia    ne e    d ri loaeeh ere a  Ie     h a t   a eel   r   y e h  t   i a  of tAras  h l tapa   nisa    h    hte   e  o   tn ht  o s sfe i  e  aae hd    a   a t hfetea i   a       tdk.. a  as    at    ee e ane  sert   o   ai stea    tee     ey aha i ea  o  \n",
      "----- diversity: 1.2\n",
      "199\n",
      "139\n",
      "----- Generating with seed: \"down Thy path Who IS Your new lady-love. Dearer to You than P Be compasionate and grant me Thy sight. Overlooking all my faults O Murari, T\"\n",
      "              rt hne    i   a eha   t d o rhe  lee a h ae tye   he ge elecn    tf e  he    y  oeee   e aat h a    eehitt i   enc   t es   ,o d  s hca itao dtioatahd   de  e  fhp t        b         i na or a   iA   a  e   t   enn e    a etse  es lan e   d hnd     th efan r   ils  c    s e aaa s   e n    t   e eda   la : t aet i hed e el  h  leino noas  ei a o   u sne e     g   a i    n  td    te n \n",
      "\n",
      "Epoch 4: loss improved from 3.08285 to 3.08258, saving model to /home/oscar47/Desktop/thinking_parrot/tp2_v0.0.1.hdf5\n",
      "4603/4603 [==============================] - 2962s 644ms/step - loss: 3.0826 - val_loss: 3.2322 - lr: 0.0013\n",
      "Epoch 5/5\n",
      "4603/4603 [==============================] - ETA: 0s - loss: 3.0830\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.1\n",
      "199\n",
      "161\n",
      "----- Generating with seed: \"ember through the songs, whither he is destined, there to be for ever: that he moeover may not forget heaven's joy, but, thinking thereon, he may attain it, thus\"\n",
      "  eeheeir an  t ti ieh   en ls a  h  hhda      odi eh moee ,     neeat e aei      ia ed t hh  a  r   tle ebi      e    ne  eh   o  odnuin h   eaa nl a eeou  ha i ee h m st dine  s aa a  a ne  w  n teaco o t h a    i  asdoa i   te a  h    , rh i    a    o  e e aa   o a  d  d e tu,a ths  n   te   i    gs ehi  e  s ee nt e hn   dd aii   ns   ose id nr  f et eetragaoetdee e,   oi eseoa i   e   ie hla \n",
      "----- diversity: 0.5\n",
      "199\n",
      "199\n",
      "----- Generating with seed: \"alse Art what beauty was of yore.LXIXThose parts of thee that the world’s eye doth viewWant nothing hat the thought of hearts can mend;All tongues, the voice of souls, give thee that due,Uttering bar\"\n",
      "  t,en  i  , t ie ir eno  a  ao e    io  h  ien         l m se     aone o r  n  ie t.  i  a eo atoo, ai  fa   eao  o ne s  e    taeoo ccm ag   h   e    eY aeah rn aei  o in  s    i    e  d    e    a   a  eh ua e oc     eu  o n   e   ie e in  n  he   t  v   n   h    o e,hdoh   eto es aatt ehn e oD ,rad te       ,    Eroeh  b        a ei   , l     eaeeeo  el    e e. onr -    addael    rbr a u se    \n",
      "----- diversity: 1.2\n",
      "199\n",
      "149\n",
      "----- Generating with seed: \"with all our might,And proved you in good sooth a noble knight;A veritable oseph, sir, you are!\"Quoth Gawayne drily, \"Thanks, Lord Potiphar!But may I\"\n",
      "e t  aeiee t   e  he ig   a   swtehn  n  eo o   r g  eBn  sfn te ihe a t   i    rro  h  ditee i ue etr  see,eg oe o mdh  ,  er   e eh  t    so e d   ls   et hen eo    e net  d e t e   ae o  neepa   re  ah   la  . aoe a e      at fet  esc faetrho      D n    i  la n d )eeo o et or  iehe  a  e e      eeer rl  nt  dsr   ih s i iho ee,esd tee e ,n    , i  to an  eae s aeH \"he  t   hn  v tt e mi eh et \n",
      "\n",
      "Epoch 5: loss did not improve from 3.08258\n",
      "4603/4603 [==============================] - 2962s 644ms/step - loss: 3.0830 - val_loss: 3.2305 - lr: 0.0013\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762b73cadbe54c7eb7f81118eb044d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='17.085 MB of 17.085 MB uploaded (0.027 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▂▁▁▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▁▅▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>3.22523</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>3.08298</td></tr><tr><td>lr</td><td>0.00129</td></tr><tr><td>val_loss</td><td>3.23046</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eager-sweep-1</strong>: <a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0/runs/rvvsrx4z\" target=\"_blank\">https://wandb.ai/oscarscholin/Thinking-Parrot2.0/runs/rvvsrx4z</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221212_102128-rvvsrx4z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4d1khhfm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_1: 189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_2: 118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_3: 235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_4: 122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_5: 74\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 70\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.17834598758622378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005155966371210286\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221212_142740-4d1khhfm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0/runs/4d1khhfm\" target=\"_blank\">gallant-sweep-2</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0/sweeps/bojamggc\" target=\"_blank\">https://wandb.ai/oscarscholin/Thinking-Parrot2.0/sweeps/bojamggc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7627/7627 [==============================] - ETA: 0s - loss: 3.0946\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.1\n",
      "199\n",
      "125\n",
      "----- Generating with seed: \"a ajyo 112 mhare ghara avo syama 120 mhamre ghara ramato hi 98 hamre ghara hota ajyo 109 mhare dere ajyo 151 mharo olagiya gh\"\n",
      "  hst ar    n reir hea     to  ti d  eo  sh e  t h      ee d a       a  aed  e  , aseo e ht  t  l ah rt oeee       e   nahe se oi t t    nd e   ioei   nnhi e a eh eru  e e  n o ei  e   toa a o o.l   aa   ani or ehetr a di   iehe aea   o e   a  i  e t e     ns           t   re hdt ee ea    eeeea n  e e  sod      ua        s naoeee   no iht s  t to    o et .aa ao on net e   htdi e  i    a s eiere a \n",
      "----- diversity: 0.5\n",
      "199\n",
      "115\n",
      "----- Generating with seed: \"canny land: the inhabitants thereof are wild and wicked: tey keep neither truce nor peace: nor do they care how the\"\n",
      "  h  n  he        ec  er   o dts n  m tr  e    lt  An ci   o   tt ea h e  e  e htnnae e tfio ln en     ar   e   c ea  ca dt, na- cre   eieeo    ea   hoe oe  e   aae it e  p    e e tae'  eo  au  nd o   e  e h     ee  oen  h     e  os  ie et e   n ra  a e e a  h e  a   e a     sdhsg   d rs hd ai    a s h  f   eeaa    nte  e       oa cag e  iee   o ne  l    o ie easth o hi   e s r heet nohop    rac  \n",
      "----- diversity: 1.2\n",
      "199\n",
      "111\n",
      "----- Generating with seed: \"ll not lapse. Why do you still make mischief 0 Master ofMira, When will You come 'f Your coming will fulfil all\"\n",
      "shn oi  eo t na  rga en t  a t a a   ei o a  oae e  eiie oee    h  ghe l ara n t ua   t     oua nee ae n  asta e nobn a  ar e   d enfs gc ei    sre ht i   i  git sa  ds eonhaf  d      o ett     eh   hc a eoin aeaea hee  e a  : sea eo kt      eg n g  to dh  np e ht h  a rO e  r mta  e   \"  e  o ano s  a oddct          ao   eenee   t  na e ra tth lt   e   eih e n  e  eaeeeam   ea nsnu ti e l    d   \n",
      "\n",
      "Epoch 1: loss did not improve from 3.08258\n",
      "7627/7627 [==============================] - 4669s 612ms/step - loss: 3.0946 - val_loss: 3.3078 - lr: 0.0052\n",
      "Epoch 2/5\n",
      "7627/7627 [==============================] - ETA: 0s - loss: 3.1042\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.1\n",
      "199\n",
      "73\n",
      "----- Generating with seed: \"rlying the wholehumour and purpose ofthe book, should have been so little\"\n",
      " e a  h m   h      f     oim      e   ec    eso e  t ee    ae     e aas n  ylroe ee dn  e       aollrde  e  r  efe    ie whaTeele   ste e   he t   uem   ,dn l i   ol.i t a h ta lteso e   ar ds  ,  e e nh     t      o             he  t s  h  h     h a  ee e i aea ,  ae ee dneh  o    pa      o  ame  a e     ea eaa e   t  ee    a e    o  tu a n e  i e e aea   ee  e aledse i   eb    n ia    a o en ae \n",
      "----- diversity: 0.5\n",
      "199\n",
      "29\n",
      "----- Generating with seed: \"puts forward a ay figure.Ther\"\n",
      " aa eemi  ht  ae t sh   t  n    e r   th    h    ts  o lT dp  e    a s   t t As   r           a rooa   tgae n   t o oe   o  e ah     e   or o     , t oo  hhu   n   i    o  d   l  a   r    t        e   s h s  oa - n -e eee ohcn  a  o dnr  n tw  eetenh     e  hennA e iamse mes he naa  ie aa fa    hen ho y t n eo    s    roe  s a  ln l a a l  a r r  om me  e oeg aeg   a e  o   ei o   rnenme a o haa d\n",
      "----- diversity: 1.2\n",
      "199\n",
      "189\n",
      "----- Generating with seed: \"to be.If eyes, corrupt by over-partial looks,Be anchor’d in the bay where all men ride,Why of ees’ falsehood hast thou forged hooks,Whereto the judgment of my heart is tied?Why should my he\"\n",
      "  eeaeuahe  a    r ao etoa   oi  h   n nro nas      i     h c  aahlh   a  e t e  ed  aa    aen a aee.o   e, n h r    th ean  liaeat   o   a  eed o se  aoe s l    ch i  o i ehiet    ia     en ft    tt     en  dae      t t h  e  ouf    t      dadt  t   s  h s    l e   t te  do othnfaeoehe  tee  o  goa     ociee s       masd   e l at g  al      r  eeeh    oai e, o e eonra  r i ni a   at  d e   h    n\n",
      "\n",
      "Epoch 2: loss did not improve from 3.08258\n",
      "7627/7627 [==============================] - 4662s 611ms/step - loss: 3.1042 - val_loss: 3.3278 - lr: 0.0052\n",
      "Epoch 3/5\n",
      "7627/7627 [==============================] - ETA: 0s - loss: 3.1063\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.1\n",
      "199\n",
      "197\n",
      "----- Generating with seed: \"hey   reaped the battle together. Their   friendship was strong as their steel; and   death walked etween them to the field.   They came on the foe like two rocks   falling from the brows of Ardven\"\n",
      " sh    i t ht  d h eheeh tai  rh a   ao     ,eu e r s   hi im     e   s      a  aef heles  t oo aneed  ih e ehrh ioaa   o    a    ie  e   e er er d,ne  eah e  lteeiaei nr ,  ed   enodtoi   tt   a   e   a    ee h  hff  s  a   n t,oaet r  o     e   efne co a ha  i   e     i  a  s   t r  na ep  e sd   ia   t   t   dto  ra o  o  e nee   a   h    e   h   ornm  eceeee i is   oa  dfd    ena e so      cea\n",
      "----- diversity: 0.5\n",
      "199\n",
      "183\n",
      "----- Generating with seed: \"occupy and perplex a ripe wit like yours,fit to break through and crush far greater obstacle? By my faith, thiscomes, not of any want of ability, but of too much indolence and toolitt\"\n",
      ", aot  a re   oa a  lt hao     y  t  e  h treeo  aeoe    hh       i    e  h e i   s o t Ate   ao     e e aettn   e    a  he    h  b e le  iemh    g  h h  a mho iie, e   su  l e d  efi  dedc        ea     entnee     nf aee h   es  a  -    teept  tn d p l n ds e al     rearn  a t   a o ca aa  a   e il htoo   ssesnee tne e  e      em ra ee oo a hee oiieh   e   eg   g e        o oet   ne eaa   a ee   \n",
      "----- diversity: 1.2\n",
      "199\n",
      "105\n",
      "----- Generating with seed: \" the judgment of some who, trespassing the bounds of heir ownignorance, use to condemn with more rigour a\"\n",
      "  ed   e    a  nt       e ce e     foh ,i  e     s eo re e et e  o   ee n    t,fa  ho    a o o   eft eesh  eeu     se w ar e ee   h s    eo n eea  d  la    re tcein   ee n   e ht e f  at    h  t  lai e   nlt  ds   ln  as  it     r      ad   o    e    tai rl t a   h s e .hhaeaa       r i e    i  ee aa te i     y      oih  ee     ag    t  eetoa     e  tt  n  ei      iaae oh   t neeheel o  s  tineeia\n",
      "\n",
      "Epoch 3: loss did not improve from 3.08258\n",
      "7627/7627 [==============================] - 4668s 612ms/step - loss: 3.1063 - val_loss: 3.3312 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "7627/7627 [==============================] - ETA: 0s - loss: 3.1065\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.1\n",
      "199\n",
      "171\n",
      "----- Generating with seed: \"with showers.    To this I witness call the fools of time,    Which die for goodness, ho have lived for crime.CXXVWere’t aught to me I bore the canopy,With my extern the o\"\n",
      "a  nn e     h  in   ue  a hs si h d, uooeeoe     o  e ahe     e ein ei   d      ei e  t  e r e dr   e e   t, i i  eh  A Hnne.ttu  o  t  s   r d   i h  t nete d iah   o a o ab  o  ta e h  ee   hi n  i en    a e  a     s o  a e  e  do    d      e  seehd a rtae  ei r c    o ee  aienieaila d   e   sehe   i     s oieeaa  tn  ehhn ot  e  o   t , ad  en      e  t i    h  e    e  nes  o   le    t   a rtc \n",
      "----- diversity: 0.5\n",
      "199\n",
      "165\n",
      "----- Generating with seed: \"ne monks withspectacles and sunshades, mounted on their tall mules; the strollers icostume bound for the next village; the barber with his basin on hishead, on his w\"\n",
      "hr     e o ar en oh e  a f    aahe ta  s  iea t eeiee a t  d   h  tr  eitl    s f         haasi aeeel ii t    ee ea a,ttaa ea hn tm  h  e    o lr    b   h  n  e   a   eia ighana oe. ne  h     it  aeue t asa e  m t  e    t  a  et oa  p      ho  a o    eps  r  e    t o etih  e   a eeda  aroneo e r   en t il     a  n   r   i to i e   be lb  a ett e  i e  efe   l      r n t cee  h a     o  iloto   i  \n",
      "----- diversity: 1.2\n",
      "199\n",
      "127\n",
      "----- Generating with seed: \"ly than the mass of humanity.The most common emotion that these cutely empathetic heroesfelt was grief, the emotion that permea\"\n",
      "        ae h i  l  in  hs  eae   t tt  A   e  t es  e   h  rdoe   h   e l oh    o noec em  .eeeaii  eeetoum  e ,  l  eu h    amr      h an no ai  eo  ehe e  oii   r         ee       s     ae    ts gi  s  s    ,la  a tt e d m  the at t  hhsenee sdec i lah ne e       at su eel ade tnlna    r  i  t  di  e .re ae ee  eh it i  f t r   aod et t tnk  h   o e  e   telel , aee tr n eadac ohs       ae teh s\n",
      "\n",
      "Epoch 4: loss did not improve from 3.08258\n",
      "7627/7627 [==============================] - 4671s 612ms/step - loss: 3.1065 - val_loss: 3.3319 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "7627/7627 [==============================] - ETA: 0s - loss: 3.1063\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.1\n",
      "199\n",
      "159\n",
      "----- Generating with seed: \"ugh the various yogic “chakras” till It reaches the “thousand-petalled lotus” inthe top of the head And there seem to be reference to yogic practices of this k\"\n",
      "  am id th  b  iu  eh rrto  l  e  o on oe ie ta io is  tld ae  siseindy a cnaire da    aieh i aenhoeht        ae   o   sd ra    gif r   d o o e  g  i  ea   aee i a r r  a he   e eeee o, d oee te r  e  t  o   e  s   dnaaee ona   o ta h aios  el hc e e  ae t    h e s oig   s oea  a   h  n i l aa eeh e      h    dc ne   hn   e  eetne  n Otoet  tee  ha    tt  rhsa     e   ee-h,h gn   eras ae   nc  ioi\n",
      "----- diversity: 0.5\n",
      "199\n",
      "167\n",
      "----- Generating with seed: \"ually the Name of Shyam 0 ye living creatures. Through repeating the Name of Shyam 1have absolved a million sms The Name of Shyam has destroyed Ancient sms of many a f\"\n",
      " nm nce  hh  a o  a hl d   a hse   e  a e    ah gl tr     reani d n    aot  n h     n    t rtat      oa   ha   e t    uihet    t   l        eoe e  a   i r      e  f htm \"  ta e Weepoo d   ae e o   rn    i  h   t oa  yae  e e    oe ttta n   i eeel e eedeo  o dl   a  o  gt t n eeh   e m   a     taleroat hr  eo  eo l h   ma  et n   e   frta  h  t     h   haeM a   D e iaoe,haa ah  ee  r a hndteei   d \n",
      "----- diversity: 1.2\n",
      "199\n",
      "61\n",
      "----- Generating with seed: \", forlorn   on the hill of stors. The wind is   heard in the \"\n",
      "      e s t  a  to  o n e if r  aaah  t  cn  a  e ieel     etade ben e i i eenett n emas ewpI    a      am    e e  itaoee de ih ea  fwal   r  i se ti  e  d  at,b      ehne    ei  tc  rn  f   eih si   e,  oh   t a  h  o   aeia l neo a ra o       n dnra    tmta   e i    rua t   e e t  eee se    sa  tes    h h oaa e   th oee  hra       ee  ae   hc   le t     lA d tteid o  d uc  h et t   n  e i ae    \n",
      "\n",
      "Epoch 5: loss did not improve from 3.08258\n",
      "7627/7627 [==============================] - 4675s 613ms/step - loss: 3.1063 - val_loss: 3.3311 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b01199f71194f1c871e38f9b29703b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>▁▇███</td></tr><tr><td>lr</td><td>██▁▁▁</td></tr><tr><td>val_loss</td><td>▁▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>3.10633</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>val_loss</td><td>3.33107</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">gallant-sweep-2</strong>: <a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0/runs/4d1khhfm\" target=\"_blank\">https://wandb.ai/oscarscholin/Thinking-Parrot2.0/runs/4d1khhfm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221212_142740-4d1khhfm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aqfvcm2s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_1: 232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_2: 87\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_3: 111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_4: 216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLSTM_layer_size_5: 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 86\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.33570917259957633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09255128357531404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/thinking_parrot/Literary-RNN/model_v0.1.0/wandb/run-20221212_205701-aqfvcm2s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0/runs/aqfvcm2s\" target=\"_blank\">chocolate-sweep-3</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Thinking-Parrot2.0/sweeps/bojamggc\" target=\"_blank\">https://wandb.ai/oscarscholin/Thinking-Parrot2.0/sweeps/bojamggc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6208/6208 [==============================] - ETA: 0s - loss: 3.3945\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.1\n",
      "199\n",
      "165\n",
      "----- Generating with seed: \"me, Jogi, smile and talk. Your lofty indifference is a sham I’ve told the whole word now, Manamohan,i To the beat of a drum Come, You with the deer-skm And the ash-s\"\n",
      "  o     ee                   e  a         s        i m     o    e   e    u             e s          ls             e        t e  I        n    e                  t    m        e sl             ts         t w      e     i               e              e                 t ol              et   el        r  s           ova           e     m l  l    v      e               t     e                        \n",
      "----- diversity: 0.5\n",
      "199\n",
      "133\n",
      "----- Generating with seed: \"ace. The blast hath lopped   my branches away; and I tremble   at te wings of the north. Prince of   the warriors, Oscur my son! shal\"\n",
      "      n   n                 ue                            e   e             l               d   e         lt                           t m     s     e  t                  o             el                         i  t      e         t    i      e          t                i     e     n ee  me     l  ee  l             l     e     e    n                          n  w  e     o       t         t    t  \n",
      "----- diversity: 1.2\n",
      "199\n",
      "143\n",
      "----- Generating with seed: \"te system as unhumanitarian, and were giving ethical and spiritual instrctions of a high order in the vernacular On the other hand the old Vedi\"\n",
      "              e    o    le     l  la   s             l      t                 l   e                    l        e                           t  n          te     e      a              e                  a       v i     n    e      t i        e        l      le   e     w  e              a  e     ne        l  i n      t               e                     e n  l t  o                                n \n",
      "\n",
      "Epoch 1: loss did not improve from 3.08258\n",
      "6208/6208 [==============================] - 4116s 662ms/step - loss: 3.3945 - val_loss: 3.6412 - lr: 0.0926\n",
      "Epoch 2/5\n",
      "6208/6208 [==============================] - ETA: 0s - loss: 3.3273\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.1\n",
      "199\n",
      "115\n",
      "----- Generating with seed: \"r sight 73 Who can understand the grief Of a woman parted rom her beloved’ Only one who has felt the pangs of absen\"\n",
      "oeeeoevoaioee eeae oe ooooooeioeoiaaoeoeoh; oeeiaea o o aiaeie oeoeoaeoeeaeo oeoieoeoeeoao ao oioooefnoaeee  e eonoms oooeenoohaeehoaaoea ei neoeooa ooonhi; oi oe ;eeehoefohoeamo  e penoeoaoa r eorofoioeneeo  aheo eeamoweneeooooehnceohoooreoo oooooooeeoowoobeto ewiieiree ee,eo ahaoeoo ;ioee eoeeoooehoe oooeeooeeehe teeioeomeheeaioeooeee eofh  e oveefoeeoeo ieio  eeaoieoet eornoeecstoa ooo ieeere o\n",
      "----- diversity: 0.5\n",
      "199\n",
      "127\n",
      "----- Generating with seed: \"er about Mira’s use of the name Rama I follow Sai Prabha in thining that she used it basi- cally as a name for Krsna, as virtua\"\n",
      "o  ooeoe ehoeoeeeemaevoeeeoeaeoieifoeeaioeeeoneeoaeieiesee n.eete,eooee eoorosnh ioowhen aeeoioaoeoeiohoee eeeoeooooeooeeoo  oeoo oitoo ooeoeehnniheoeeeilan nroooeeeao oooeo voeeoooehienc oefiheo eoaoioooee ieeeoienae eaeeeeo eio e oonmioo eeaorro;eio eeoheeeteon eeoheeeifooo eiaeleeaieoeaoet fnooe eeem oie e earoweoioho foiim  eoenoooefmehe esiy  nheeooeetooefeaonao rfioeeooo ofieloonetemoe eoien\n",
      "----- diversity: 1.2\n",
      "199\n",
      "111\n",
      "----- Generating with seed: \"ition of Northern India, of whom more must be said belowPerhaps too much should not be made of this connection.\"\n",
      "eo eoieioa oeve eevoneoaan neeir oeone oonooo ooeoveeoeo ooomiooetoeeeoeenheooawoooeeeooe areoeoeeeeeeahaloiierveeeeeooeeooooohooefhre e oooviieeeoeiwoeieoleeooreho aoeaoaoioeoeeeee eea;e ooo ieedooaeeofienheeaoe o iiihmoe  ie eaoi o re eeeoeoaevocsvoeoe oeioonoeooeaGehofn oeee o iomr iaemoevehoiiioeaoelsaenoieiem;ee oheoeeoee eooieoeho oeeoooe e enaaowineiiwtoaernea eoefereaeenhhoavearoaeeeee eeo\n",
      "\n",
      "Epoch 2: loss did not improve from 3.08258\n",
      "6208/6208 [==============================] - 4116s 663ms/step - loss: 3.3273 - val_loss: 3.7221 - lr: 0.0926\n",
      "Epoch 3/5\n",
      " 357/6208 [>.............................] - ETA: 57:07 - loss: 3.3478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7f9e57247160> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_communicate_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMessageFuture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 385/6208 [>.............................] - ETA: 56:52 - loss: 3.3421"
     ]
    }
   ],
   "source": [
    "# file to train network\n",
    "# @oscars47\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "from wandb.keras import *\n",
    "\n",
    "# check GPU num\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "from dataprep2 import TextData # import TextData class for processing\n",
    "from modelpredict2 import * # get functions to interpret output\n",
    "\n",
    "# define path\n",
    "MAIN_DIR = '/home/oscar47/Desktop/thinking_parrot'\n",
    "DATA_DIR = os.path.join(MAIN_DIR, 'texts_prep') # main\n",
    "# DATA_DIR = os.path.join(MAIN_DIR, 'texts_prep', 'test') # for testing\n",
    "\n",
    "# define master txt file\n",
    "MASTER_TEXT_PATH = os.path.join(MAIN_DIR, 'texts', 'master.txt')\n",
    "#MASTER_TEXT_PATH = os.path.join(MAIN_DIR, 'texts', 'toaster_man.txt')\n",
    "\n",
    "# initialize text object\n",
    "maxChar = 100\n",
    "master=TextData(MASTER_TEXT_PATH, maxChar)\n",
    "# get alphabet\n",
    "alphabet = master.alphabet\n",
    "char_to_int= master.char_to_int\n",
    "int_to_char = master.int_to_char\n",
    "text = master.text\n",
    "\n",
    "# read in files for training\n",
    "x_train = np.load(os.path.join(DATA_DIR, 'x_train.npy'))\n",
    "y_train = np.load(os.path.join(DATA_DIR, 'y_train.npy'))\n",
    "x_val = np.load(os.path.join(DATA_DIR, 'x_val.npy'))\n",
    "y_val = np.load(os.path.join(DATA_DIR, 'y_val.npy'))\n",
    "\n",
    "# build model functions--------------------------------\n",
    "def build_model(LSTM_layer_size_1,  LSTM_layer_size_2, LSTM_layer_size_3, \n",
    "          LSTM_layer_size_4, LSTM_layer_size_5, \n",
    "          dropout, learning_rate):\n",
    "    # call initialize function\n",
    "    \n",
    "    model = Sequential()\n",
    "    # RNN layers for language processing\n",
    "    model.add(LSTM(LSTM_layer_size_1, input_shape = (2*maxChar, len(alphabet)), return_sequences=True))\n",
    "    model.add(LSTM(LSTM_layer_size_2, return_sequences=True))\n",
    "    model.add(LSTM(LSTM_layer_size_3, return_sequences=True))\n",
    "    model.add(LSTM(LSTM_layer_size_4, return_sequences=True))\n",
    "    model.add(LSTM(LSTM_layer_size_5))\n",
    "\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(len(alphabet)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    # put structure together\n",
    "    optimizer = RMSprop(learning_rate = learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    return model\n",
    "\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "    # If called by wandb.agent, as below,\n",
    "    # this config will be set by Sweep Controller\n",
    "      config = wandb.config\n",
    "\n",
    "      #pprint.pprint(config)\n",
    "\n",
    "      #initialize the neural net; \n",
    "      global model\n",
    "      model = build_model(config.LSTM_layer_size_1,  config.LSTM_layer_size_2, config.LSTM_layer_size_3, \n",
    "              config.LSTM_layer_size_4, config.LSTM_layer_size_5, \n",
    "              config.dropout, config.learning_rate)\n",
    "      \n",
    "      #now run training\n",
    "      history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size = config.batch_size,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=config.epochs,\n",
    "        callbacks=callbacks #use callbacks to have w&b log stats; will automatically save best model                     \n",
    "      ) \n",
    "\n",
    "def train_custom(LSTM_layer_size_1=128,  LSTM_layer_size_2=128, LSTM_layer_size_3=128, \n",
    "              LSTM_layer_size_4=128, LSTM_layer_size_5=128, \n",
    "              dropout=0.1, learning_rate=0.01, epochs=1, batchsize=32):\n",
    "    #initialize the neural net; \n",
    "    global model\n",
    "    model = build_model(LSTM_layer_size_1,  LSTM_layer_size_2, LSTM_layer_size_3, \n",
    "            LSTM_layer_size_4, LSTM_layer_size_5, \n",
    "            dropout, learning_rate)\n",
    "    \n",
    "    #now run training\n",
    "    history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size = batchsize,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks #use callbacks to have w&b log stats; will automatically save best model                     \n",
    "    ) \n",
    "\n",
    "\n",
    "# helper functions from Keras\n",
    "\n",
    "def get_toast_len(mean, stdev):\n",
    "    toast_len = int(np.random.normal(mean, stdev))\n",
    "    return toast_len\n",
    "\n",
    "# do this each time we begin a new epoch    \n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "\n",
    "    for diversity in [0.1, 0.5,1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        start_index = np.random.randint(0, len(text) - maxChar - 1) +1\n",
    "        # need to check how much to pad\n",
    "        if start_index < maxChar:\n",
    "            sentence0 = text[0:start_index] # up to but not including start index\n",
    "            sentence1 = text[start_index+1: start_index+start_index+1]\n",
    "            sentence = sentence0+sentence1\n",
    "        else:\n",
    "            stdev = (1/2)*(maxChar - 1)\n",
    "            mean = (maxChar - 1)\n",
    "                 # compute len, following normal distribution between 1 and maxChar; will go from [:num] as first part then [num+1:] concatenated; predict at num\n",
    "                # need toastlen positive but no more than  maxChar\n",
    "            goodtoast = False\n",
    "            while goodtoast==False:\n",
    "                toast_len = get_toast_len(mean, stdev)\n",
    "                # add 1 to len since the distr here goes from 0 up to maxChar-1\n",
    "                toast_len+=1\n",
    "                #print(toast_len)\n",
    "                if (toast_len > 0) and (toast_len <= maxChar): # if get acceptable toast, can leave\n",
    "                    goodtoast=True\n",
    "                    break\n",
    "            sentence0 = text[start_index-toast_len:start_index]\n",
    "            sentence1 = text[start_index+1: start_index+toast_len]\n",
    "            sentence =  sentence0+ sentence1\n",
    "        \n",
    "        # need another condition here about if neat the end\n",
    "\n",
    "        # 1. compute difference from maxChar and len/2\n",
    "        diff = maxChar - int(len(sentence)/2)\n",
    "        # need to check even/odd so we don;t overcount\n",
    "        if len(sentence) %2 != 0: # if odd: need to subtract 1\n",
    "            diff-=1\n",
    "\n",
    "        # 2. initialize new string for each sentence\n",
    "        complete_sentence = ''\n",
    "        for i in range(diff):\n",
    "            complete_sentence+='£' # appending forbidden\n",
    "        # 3. now add 'real' sentence\n",
    "        complete_sentence+=sentence\n",
    "        # 4. append forbidden again\n",
    "        for i in range(diff):\n",
    "            complete_sentence+='£'\n",
    "\n",
    "        print(len(complete_sentence))\n",
    "        print(len(sentence))\n",
    "\n",
    "        generated = ''\n",
    "        #generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        #sys.stdout.write(generated)\n",
    "\n",
    "        # generate 400 characters worth of test\n",
    "        for i in range(400):\n",
    "            # prepare chosen sentence as part of new dataset\n",
    "            x_pred = np.zeros((1, 2*maxChar, len(alphabet)))\n",
    "            #x_pred = np.zeros((2*maxChar, len(alphabet)))\n",
    "            for t, char in enumerate(complete_sentence):\n",
    "                if char != '£': # encode 1 iff it's not padded\n",
    "                    x_pred[0, t, char_to_int[char]] = 1.\n",
    "                    #x_pred[t, char_to_int[char]] = 1.\n",
    "\n",
    "            # use the current model to predict what outputs are\n",
    "            preds = model.predict(x_pred, verbose=0)[0] # removed [0] here\n",
    "            # call the function above to interpret the probabilities and add a degree of freedom\n",
    "            next_index = sample(preds, diversity)\n",
    "            #convert predicted number to character\n",
    "            next_char = int_to_char[next_index]\n",
    "\n",
    "            generated+=next_char\n",
    "\n",
    "            # check size of sentence; if still small can keep old stuff in sentence0\n",
    "            if len(sentence) >= 2*maxChar:\n",
    "                sentence0 = sentence0[1:]\n",
    "            sentence0 += next_char # append new middle character\n",
    "            sentence=sentence0+sentence1 # append to main sentence\n",
    "\n",
    "            # print the new character as we create it\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "# define search parameters-----------------\n",
    "# holds wandb config nested dictionaries\n",
    "# @oscars47\n",
    "\n",
    "# set dictionary with random search; optimizing val_loss\n",
    "sweep_config= {\n",
    "    'method': 'random',\n",
    "    'name': 'val_loss',\n",
    "    'goal': 'minimize'\n",
    "}\n",
    "\n",
    "sweep_config['metric']= 'val_loss'\n",
    "\n",
    "# now name hyperparameters with nested dictionary\n",
    "parameters_dict = {\n",
    "    'epochs': {\n",
    "       'value':5\n",
    "    },\n",
    "    # for build_dataset\n",
    "     'batch_size': {\n",
    "       'distribution': 'int_uniform',  #we want to specify a distribution type to more efficiently iterate through these hyperparams\n",
    "       'min': 64,\n",
    "       'max': 128\n",
    "    },\n",
    "    'LSTM_layer_size_1': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'LSTM_layer_size_2': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'LSTM_layer_size_3': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'LSTM_layer_size_4': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'LSTM_layer_size_5': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "     'dropout': {\n",
    "             'distribution': 'uniform',\n",
    "       'min': 0,\n",
    "       'max': 0.6\n",
    "    },\n",
    "    'learning_rate':{\n",
    "         #uniform distribution between 0 and 1\n",
    "         'distribution': 'uniform', \n",
    "         'min': 0,\n",
    "         'max': 0.1\n",
    "     }\n",
    "}\n",
    "\n",
    "# append parameters to sweep config\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "# login to wandb-------------------------\n",
    "wandb.init(project=\"Thinking-Parrot2.0-1\", entity=\"oscarscholin\")\n",
    "\n",
    "# finish with callbacks------------\n",
    "# use the two helper functions above to create the LambdaCallback \n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "# define two other callbacks\n",
    "# save model\n",
    "# if no directory \"models\" exists, create it\n",
    "if not(os.path.exists(os.path.join(MAIN_DIR, 'models'))):\n",
    "    os.mkdir(os.path.join(MAIN_DIR, 'models'))\n",
    "modelpath = os.path.join(MAIN_DIR, \"tp2_v0.0.1.hdf5\")\n",
    "checkpoint = ModelCheckpoint(modelpath, monitor='loss',\n",
    "                             verbose=1, save_best_only=True,\n",
    "                             mode='min')\n",
    "# if learning stals, reduce the LR\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)\n",
    "\n",
    "# compile the callbacks\n",
    "callbacks = [print_callback, checkpoint, reduce_lr, WandbCallback()]\n",
    "# callbacks = [print_callback, checkpoint, reduce_lr]\n",
    "\n",
    "# initialize sweep!\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"Thinking-Parrot2.0-1\", entity=\"oscarscholin\")\n",
    "\n",
    "# 'train' tells agent function is train\n",
    "# 'count': number of times to run this\n",
    "wandb.agent(sweep_id, train, count=100)\n",
    "\n",
    "#train_custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14577, 200, 68)\n",
      "(3643, 200, 68)\n",
      "(14577, 68)\n",
      "(3643, 68)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aaf8a3611b879056867134183afc22ea709e115b10fb7684e1dbf805b3500c4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
